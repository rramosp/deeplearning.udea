# 03 - TENSORFLOW CORE

## ¿Qué es el cómputo simbólico?
**01 - Introducción al cómputo simbólico**: [Video 10mins](https://youtu.be/EnQ-peKXjCY) <br/>Introducimos qué es y para qué sirve el cómputo simbólico, usando [`sympy`](https://www.sympy.org).

**02 - Grafos computacionales**: [Video 18mins](https://youtu.be/nSL1_yyBa7Q) <br/>Explicamos la noción de grafo computacional, que es central en Tensorflow, y la necesidad de alinear la manipulación simbólica de expresiones con la capacidad de ejecución de código.

**03 - Obtención automática del gradiente para regresión lineal**: [Video 15mins](https://youtu.be/hrEgwg9I0YE) <br/>Ilustramos cómo podemos obtener el gradiente de una función de costo (o de pérdida) con herramientas estándar de cómputo simbólico.

## Cómputo simbólico con `Tensorflow`

**04 - Tensorflow Overview**: [Video 13mins](https://youtu.be/W7y2RS8jUUY) <br/>Describimos la organización general de Tensorflow.

**05 - Cómputo simbólico en `Tensorflow`**: [Video 10mins](https://youtu.be/LH_qSSLXaNA) <br/>Mostramos cómo Tensorflow manipula expresiones simbólicas.

**06 - ¿Qué es un tensor?**: [Video 14mins](https://youtu.be/kaqeXc5FQGo) <br/>Desarrollamos un ejemplo de cálculo del gradiente con tensores.

**07 - Custom implementations**: [Video 21mins](https://youtu.be/KmmGBVrdwVU) <br/>Mostramos cómo integrar con Tensorflow nuestras propias implementaciones de los distintos componentes del proceso de construcción y entrenamiento de un modelo, usando toda la potencial del motor simbólico de Tensorflow.

**08 - Necesidad de `tf.funcion`**: [Video 11mins](https://youtu.be/dPFqnZ5xfF8) <br/>Explicamos qué es `tf.function` y como contribuye a la eficiencia de la evalución de expresiones simbólicas.

**09 - Rendimiento de `tf.function`**: [Video 16mins](https://youtu.be/lcDsF5ecdrw) <br/>Realizamos varios experimentos para entender en qué circunstancias podemos usar `tf.function`.

## Batch normalization

**10 - Histogramas de activaciones**: [Video 10mins](https://youtu.be/-uuFHUl-SXk) <br/>Describimos cómo se construyen los histogramas de activaciones de cada capa con cada batch de datos, para inspeccionar la evolución de una red neuronal durante el entrenamiento.

**11 - Covariate shift**: [Video 12mins](https://youtu.be/mQBanXHZSNI)<br/>Explicamos la intuición detrás del covariate shift y por qué es importante en el contexto de deep learning.

**12 - Batch normalization**: [Video 15mins](https://youtu.be/YN1U9yz8aSI)<br/>Mostramos como a través de batch normalization controlamos las distribuciones de entrada a distintos puntos de una red neuronal y desarrollamos un experimento para verificarlo en la práctica.

## LABORATORIOS

**LAB 1 - Tensorflow subclassing**: [Video 5mins](https://youtu.be/2gE9yjl5T5o)<br/>Laboratorio para crear un modelo estándar de Tensorflow.

**LAB 2 - Tensorflow low level**: [Video 11mins](https://youtu.be/oWzuEOCGe7Q)<br/>Laboratorio para adquirir práctica con la manipulación de modelos y gradientes en Tensorflow.
